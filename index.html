<html>
  <head>
    <meta charset="utf-8" />
    <meta
      http-equiv="Cache-control"
      content="no-cache, no-store, must-revalidate"
    />
    <meta http-equiv="Pragma" content="no-cache" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, user-scalable=no"
    />
    <title>EskanoGroup</title>
    <link
      href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css"
      rel="stylesheet"
    />
    <!-- script and css added -->
    <link rel="stylesheet" href="./style.css" />
    <script src="./uploader.js"></script>
    <!-- bootstrap add -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
      integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm"
      crossorigin="anonymous"
    />
    <script
      src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
      integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js"
      integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js"
      integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
      crossorigin="anonymous"
    ></script>

    <script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
  </head>
  <body>
    <nav class="navbar navbar-light bg-light">
      <a class="navbar-brand" href="#">FaceMesh App</a>
    </nav>
    <div class="container-fluid">
      <section id="demos" class="invisible">

      <div class="row">
        <div class="col-sm-12 col-md-6 col-lg-6">
          <div class="detectOnClick" style="width: 100%;">
            <img src="./maryammirzakhani.jpg" id="output_image"  width="70%" crossorigin="anonymous" title="Click to get detection!" />
            <input type="file" accept="image/*"  onchange="preview_image(event)">
          </div>
        </div>
        <div class="col-sm-12 col-md-6 col-lg-6">
          <div class="blend-shapes details-custom">
            <h2>Content</h2>
            <hr>
            <ul class="blend-shapes-list" id="image-blend-shapes"></ul>
          </div>
        </div>
      </div>
    </section>

    </div>
<!-- 
  <section id="demos" class="invisible">

    <div class="detectOnClick">
      <img src="./portrait.jpg" id="output_image" class="img-thumbnail img-fluid" width="70%" crossorigin="anonymous" title="Click to get detection!" />
      <input type="file" accept="image/*"  onchange="preview_image(event)">
    </div>
    <div class="blend-shapes details-custom">
      <ul class="blend-shapes-list" id="image-blend-shapes"></ul>
    </div>
  </section> -->
    

    <!-- Video section -->
    <!-- <h2>Demo: Webcam continuous face landmarks detection</h2>
    <p>Hold your face in front of your webcam to get real-time face landmarker detection.</br>Click <b>enable webcam</b> below and grant access to the webcam if prompted.</p>

    <div id="liveView" class="videoView">
      <button id="webcamButton" class="mdc-button mdc-button--raised">
        <span class="mdc-button__ripple"></span>
        <span class="mdc-button__label">ENABLE WEBCAM</span>
      </button>
      <div style="position: relative;">
        <video id="webcam" style="position: abso" autoplay playsinline></video>
        <canvas class="output_canvas" id="output_canvas" style="position: absolute; left: 0px; top: 0px;"></canvas>
      </div>
    </div> -->
    <!-- 
    <div class="blend-shapes">
      <ul class="blend-shapes-list" id="video-blend-shapes"></ul>
    </div> -->

    <script type="module">
      import vision from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

      const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;
      const demosSection = document.getElementById("demos");
      const imageBlendShapes = document.getElementById("image-blend-shapes");
      const videoBlendShapes = document.getElementById("video-blend-shapes");

      let faceLandmarker;
      let runningMode = "IMAGE" | "VIDEO";
      let enableWebcamButton = HTMLButtonElement;
      let webcamRunning = (Boolean = false);
      const videoWidth = 480;

      // Before we can use HandLandmarker class we must wait for it to finish
      // loading. Machine Learning models can be large and take a moment to
      // get everything needed to run.
      async function runDemo() {
        // Read more `CopyWebpackPlugin`, copy wasm set from "https://cdn.skypack.dev/node_modules" to `/wasm`
        const filesetResolver = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
        );
        faceLandmarker = await FaceLandmarker.createFromOptions(
          filesetResolver,
          {
            baseOptions: {
              modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
              delegate: "GPU",
            },
            outputFaceBlendshapes: true,
            runningMode,
            numFaces: 1,
          }
        );
        demosSection.classList.remove("invisible");
      }
      runDemo();

      /********************************************************************
// Demo 1: Grab a bunch of images from the page and detection them
// upon click.
********************************************************************/

      // In this demo, we have put all our clickable images in divs with the
      // CSS class 'detectionOnClick'. Lets get all the elements that have
      // this class.
      const imageContainers = document.getElementsByClassName("detectOnClick");

      // Now let's go through all of these and add a click event listener.
      for (let i = 0; i < imageContainers.length; i++) {
        // Add event listener to the child element whichis the img element.
        imageContainers[i].children[0].addEventListener("click", handleClick);
      }

      // When an image is clicked, let's detect it and display results!
      async function handleClick(event) {
        if (!faceLandmarker) {
          console.log("Wait for faceLandmarker to load before clicking!");
          return;
        }

        if (runningMode === "VIDEO") {
          runningMode = "IMAGE";
          await faceLandmarker.setOptions({ runningMode });
        }
        // Remove all landmarks drawed before
        const allCanvas =
          event.target.parentNode.getElementsByClassName("canvas");
        for (var i = allCanvas.length - 1; i >= 0; i--) {
          const n = allCanvas[i];
          n.parentNode.removeChild(n);
        }

        // We can call faceLandmarker.detect as many times as we like with
        // different image data each time. This returns a promise
        // which we wait to complete and then call a function to
        // print out the results of the prediction.
        const faceLandmarkerResult = faceLandmarker.detect(event.target);
        const canvas = document.createElement("canvas");
        canvas.setAttribute("class", "canvas");
        canvas.setAttribute("width", event.target.naturalWidth + "px");
        canvas.setAttribute("height", event.target.naturalHeight + "px");
        canvas.style.left = "0px";
        canvas.style.top = "0px";
        canvas.style.width = `${event.target.width}px`;
        canvas.style.height = `${event.target.height}px`;

        event.target.parentNode.appendChild(canvas);
        const ctx = canvas.getContext("2d");
        const drawingUtils = new DrawingUtils(ctx);
        for (const landmarks of faceLandmarkerResult.faceLandmarks) {
          drawingUtils.drawConnectors(
            landmarks,
            FaceLandmarker.FACE_LANDMARKS_TESSELATION,
            { color: "#C0C0C070", lineWidth: 1 }
          );
          drawingUtils.drawConnectors(
            landmarks,
            FaceLandmarker.FACE_LANDMARKS_RIGHT_EYE,
            { color: "#FF3030" }
          );
          drawingUtils.drawConnectors(
            landmarks,
            FaceLandmarker.FACE_LANDMARKS_RIGHT_EYEBROW,
            { color: "#FF3030" }
          );
          drawingUtils.drawConnectors(
            landmarks,
            FaceLandmarker.FACE_LANDMARKS_LEFT_EYE,
            { color: "#30FF30" }
          );
          drawingUtils.drawConnectors(
            landmarks,
            FaceLandmarker.FACE_LANDMARKS_LEFT_EYEBROW,
            { color: "#30FF30" }
          );
          drawingUtils.drawConnectors(
            landmarks,
            FaceLandmarker.FACE_LANDMARKS_FACE_OVAL,
            { color: "#E0E0E0" }
          );
          drawingUtils.drawConnectors(
            landmarks,
            FaceLandmarker.FACE_LANDMARKS_LIPS,
            {
              color: "#E0E0E0",
            }
          );
          drawingUtils.drawConnectors(
            landmarks,
            FaceLandmarker.FACE_LANDMARKS_RIGHT_IRIS,
            { color: "#FF3030" }
          );
          drawingUtils.drawConnectors(
            landmarks,
            FaceLandmarker.FACE_LANDMARKS_LEFT_IRIS,
            { color: "#30FF30" }
          );
        }
        drawBlendShapes(imageBlendShapes, faceLandmarkerResult.faceBlendshapes);
      }

      /********************************************************************
// Demo 2: Continuously grab image from webcam stream and detect it.
********************************************************************/

      const video = document.getElementById("webcam");
      const canvasElement = document.getElementById("output_canvas");

      const canvasCtx = canvasElement.getContext("2d");

      // Check if webcam access is supported.
      function hasGetUserMedia() {
        return !!(
          navigator.mediaDevices && navigator.mediaDevices.getUserMedia
        );
      }

      // If webcam supported, add event listener to button for when user
      // wants to activate it.
      if (hasGetUserMedia()) {
        enableWebcamButton = document.getElementById("webcamButton");
        enableWebcamButton.addEventListener("click", enableCam);
      } else {
        console.warn("getUserMedia() is not supported by your browser");
      }

      // Enable the live webcam view and start detection.
      function enableCam(event) {
        if (!faceLandmarker) {
          console.log("Wait! faceLandmarker not loaded yet.");
          return;
        }

        if (webcamRunning === true) {
          webcamRunning = false;
          enableWebcamButton.innerText = "ENABLE PREDICTIONS";
        } else {
          webcamRunning = true;
          enableWebcamButton.innerText = "DISABLE PREDICTIONS";
        }

        // getUsermedia parameters.
        const constraints = {
          video: true,
        };

        // Activate the webcam stream.
        navigator.mediaDevices
          .getUserMedia(constraints)
          .then(function (stream) {
            video.srcObject = stream;
            video.addEventListener("loadeddata", predictWebcam);
          });
      }

      let lastVideoTime = -1;
      let results = undefined;
      const drawingUtils = new DrawingUtils(canvasCtx);
      async function predictWebcam() {
        const radio = video.videoHeight / video.videoWidth;
        video.style.width = videoWidth + "px";
        video.style.height = videoWidth * radio + "px";
        canvasElement.style.width = videoWidth + "px";
        canvasElement.style.height = videoWidth * radio + "px";
        canvasElement.width = video.videoWidth;
        canvasElement.height = video.videoHeight;
        // Now let's start detecting the stream.
        if (runningMode === "IMAGE") {
          runningMode = "VIDEO";
          await faceLandmarker.setOptions({ runningMode: runningMode });
        }
        let nowInMs = Date.now();
        if (lastVideoTime !== video.currentTime) {
          lastVideoTime = video.currentTime;
          results = faceLandmarker.detectForVideo(video, nowInMs);
        }
        if (results.faceLandmarks) {
          for (const landmarks of results.faceLandmarks) {
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_TESSELATION,
              { color: "#C0C0C070", lineWidth: 1 }
            );
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_RIGHT_EYE,
              { color: "#FF3030" }
            );
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_RIGHT_EYEBROW,
              { color: "#FF3030" }
            );
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_LEFT_EYE,
              { color: "#30FF30" }
            );
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_LEFT_EYEBROW,
              { color: "#30FF30" }
            );
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_FACE_OVAL,
              { color: "#E0E0E0" }
            );
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_LIPS,
              { color: "#E0E0E0" }
            );
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_RIGHT_IRIS,
              { color: "#FF3030" }
            );
            drawingUtils.drawConnectors(
              landmarks,
              FaceLandmarker.FACE_LANDMARKS_LEFT_IRIS,
              { color: "#30FF30" }
            );
          }
        }
        drawBlendShapes(videoBlendShapes, results.faceBlendshapes);

        // Call this function again to keep predicting when the browser is ready.
        if (webcamRunning === true) {
          window.requestAnimationFrame(predictWebcam);
        }
      }

      function drawBlendShapes(el = HTMLCanvasElement, blendShapes = any[{}]) {
        if (!blendShapes.length) {
          return;
        }

        let htmlMaker = "";
        blendShapes[0].categories.map((shape) => {
          htmlMaker += `
      <li class="blend-shapes-item">
        <span class="blend-shapes-label">${
          shape.displayName || shape.categoryName
        }</span>
        <span class="blend-shapes-value" style="width: calc(${
          +shape.score * 100
        }% - 120px)">${(+shape.score).toFixed(4)}</span>
      </li>
    `;
        });

        el.innerHTML = htmlMaker;
      }
    </script>
  </body>
</html>
